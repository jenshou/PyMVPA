{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nipy\n",
    "from mvpa2.suite import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(subject_number):\n",
    "    \"\"\"Returns an fmri dataset object containing data of all 10 runs for a particular subject.\"\"\"\n",
    "    \n",
    "    cwd = '/home/fmri-data'\n",
    "    data_path = os.path.join(cwd,\"mvpa_\"+str(subject_number))\n",
    "\n",
    "    # Load the sample attributes\n",
    "    attr_fname = \"targets_attr_mvpa_\"+str(subject_number)+\".txt\"\n",
    "    attr_path = os.path.join(data_path, attr_fname)\n",
    "    attr = SampleAttributes(attr_path) # PyMVPA convenience function to read attribute files.\n",
    "\n",
    "    # Load all 10 runs from one subject into one fMRI dataset\n",
    "    file_path_list = list() # file path list to each run\n",
    "    for i in range(1,11):\n",
    "        run_name = \"run\"+str(i)\n",
    "        fname = run_name +\"_native.nii.gz\"\n",
    "        filepath = os.path.join(data_path, fname)\n",
    "        file_path_list.append(filepath)\n",
    "\n",
    "    # fMRI dataset format is convenient and vital for using PyMVPA.\n",
    "    ds = fmri_dataset(file_path_list,targets=attr.targets,chunks=attr.chunks)\n",
    "    return ds\n",
    "if __debug__:\n",
    "    debug.active += [\"SLC\"]\n",
    "\n",
    "ds = load_data(1)\n",
    "first_ds = ds\n",
    "poly_detrend(ds, polyord=1, chunks_attr='chunks')\n",
    "zscore(ds, param_est=('targets', ['baseline_catch_all']), chunks_attr='chunks')\n",
    "ds_dropped = ds[ds.sa.targets != 'baseline_catch_all']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = FeatureSelectionClassifier(SMLR(), \n",
    "                                 SensitivityBasedFeatureSelection(\n",
    "                                     SMLRWeights(SMLR(lm=1.0), \n",
    "                                                 postproc=sumofabs_sample()),\n",
    "                                     FixedNElementTailSelector(1000, \n",
    "                                                               tail='upper', \n",
    "                                                               mode='select')))  \n",
    "# clf = SMLRWeights(SMLR(), force_train=True)\n",
    "clf.train(ds_dropped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0,  0,  0],\n",
       "       [ 0,  0,  1],\n",
       "       [ 0,  0,  2],\n",
       "       ...,\n",
       "       [73, 73, 30],\n",
       "       [73, 73, 31],\n",
       "       [73, 73, 32]])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selected_voxels = clf.mapper.forward(ds_dropped)\n",
    "ds_dropped.fa.voxel_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten_index(voxel_index):\n",
    "    return voxel_index[0] * 74 * 33 + voxel_index[1] * 33 + voxel_index[2]\n",
    "important_flatindexes = []\n",
    "for indice in selected_voxels.fa.voxel_indices:\n",
    "    important_flatindexes.append(flatten_index(indice))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# important_flatindexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000  volume done\n",
      "20000  volume done\n",
      "30000  volume done\n",
      "40000  volume done\n",
      "50000  volume done\n",
      "60000  volume done\n",
      "70000  volume done\n",
      "80000  volume done\n",
      "90000  volume done\n",
      "100000  volume done\n",
      "110000  volume done\n",
      "120000  volume done\n",
      "130000  volume done\n",
      "140000  volume done\n",
      "150000  volume done\n",
      "160000  volume done\n",
      "170000  volume done\n",
      "180000  volume done\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "# for volume in ds.samples:\n",
    "for i, vox in enumerate(ds_dropped.samples[150]):\n",
    "    if i in important_flatindexes:\n",
    "        vox = 10000\n",
    "    else:\n",
    "        vox = 0\n",
    "    count += 1\n",
    "    if count % 10000 == 0:\n",
    "        print count, ' volume done'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* map sensitivities back to nifti image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fds = clf.mapper.forward(ds)\n",
    "mynii_fds = map2nifti(fds, ds.samples)\n",
    "mynii_fds.to_filename('ec2_1k_zero.nii.gz')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
